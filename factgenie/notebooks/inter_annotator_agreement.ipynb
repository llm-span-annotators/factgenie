{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9670.12s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pygamma-agreement in /lnet/work/people/kasner/virtualenv/factgenie/lib/python3.10/site-packages (0.5.9)\n",
      "Requirement already satisfied: cylp in /lnet/work/people/kasner/virtualenv/factgenie/lib/python3.10/site-packages (0.92.3)\n",
      "Requirement already satisfied: pandas in /lnet/work/people/kasner/virtualenv/factgenie/lib/python3.10/site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy in /lnet/work/people/kasner/virtualenv/factgenie/lib/python3.10/site-packages (1.26.4)\n",
      "Requirement already satisfied: tqdm in /lnet/work/people/kasner/virtualenv/factgenie/lib/python3.10/site-packages (4.66.4)\n",
      "Requirement already satisfied: scipy in /lnet/work/people/kasner/virtualenv/factgenie/lib/python3.10/site-packages (1.14.1)\n",
      "Requirement already satisfied: sortedcontainers>=2.0.4 in /lnet/work/people/kasner/virtualenv/factgenie/lib/python3.10/site-packages (from pygamma-agreement) (2.4.0)\n",
      "Requirement already satisfied: pyannote.core>=4.1 in /lnet/work/people/kasner/virtualenv/factgenie/lib/python3.10/site-packages (from pygamma-agreement) (5.0.0)\n",
      "Requirement already satisfied: cvxpy>=1.0.25 in /lnet/work/people/kasner/virtualenv/factgenie/lib/python3.10/site-packages (from pygamma-agreement) (1.6.0)\n",
      "Requirement already satisfied: cvxopt==1.3.2 in /lnet/work/people/kasner/virtualenv/factgenie/lib/python3.10/site-packages (from pygamma-agreement) (1.3.2)\n",
      "Requirement already satisfied: numba>=0.54.0 in /lnet/work/people/kasner/virtualenv/factgenie/lib/python3.10/site-packages (from pygamma-agreement) (0.60.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /lnet/work/people/kasner/virtualenv/factgenie/lib/python3.10/site-packages (from pygamma-agreement) (4.11.0)\n",
      "Requirement already satisfied: TextGrid>=1.5 in /lnet/work/people/kasner/virtualenv/factgenie/lib/python3.10/site-packages (from pygamma-agreement) (1.6.1)\n",
      "Requirement already satisfied: pympi-ling>=1.69 in /lnet/work/people/kasner/virtualenv/factgenie/lib/python3.10/site-packages (from pygamma-agreement) (1.70.2)\n",
      "Requirement already satisfied: pyannote.database>=4.1 in /lnet/work/people/kasner/virtualenv/factgenie/lib/python3.10/site-packages (from pygamma-agreement) (5.1.3)\n",
      "Requirement already satisfied: hypothesis in /lnet/work/people/kasner/virtualenv/factgenie/lib/python3.10/site-packages (from cylp) (6.124.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /lnet/work/people/kasner/virtualenv/factgenie/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /lnet/work/people/kasner/virtualenv/factgenie/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /lnet/work/people/kasner/virtualenv/factgenie/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: osqp>=0.6.2 in /lnet/work/people/kasner/virtualenv/factgenie/lib/python3.10/site-packages (from cvxpy>=1.0.25->pygamma-agreement) (0.6.7.post3)\n",
      "Requirement already satisfied: clarabel>=0.5.0 in /lnet/work/people/kasner/virtualenv/factgenie/lib/python3.10/site-packages (from cvxpy>=1.0.25->pygamma-agreement) (0.9.0)\n",
      "Requirement already satisfied: scs>=3.2.4.post1 in /lnet/work/people/kasner/virtualenv/factgenie/lib/python3.10/site-packages (from cvxpy>=1.0.25->pygamma-agreement) (3.2.7.post2)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /lnet/work/people/kasner/virtualenv/factgenie/lib/python3.10/site-packages (from numba>=0.54.0->pygamma-agreement) (0.43.0)\n",
      "Requirement already satisfied: pyYAML>=3.12 in /lnet/work/people/kasner/virtualenv/factgenie/lib/python3.10/site-packages (from pyannote.database>=4.1->pygamma-agreement) (6.0.2)\n",
      "Requirement already satisfied: typer>=0.12.1 in /lnet/work/people/kasner/virtualenv/factgenie/lib/python3.10/site-packages (from pyannote.database>=4.1->pygamma-agreement) (0.15.1)\n",
      "Requirement already satisfied: six>=1.5 in /lnet/work/people/kasner/virtualenv/factgenie/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /lnet/work/people/kasner/virtualenv/factgenie/lib/python3.10/site-packages (from hypothesis->cylp) (23.2.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0 in /lnet/work/people/kasner/virtualenv/factgenie/lib/python3.10/site-packages (from hypothesis->cylp) (1.2.1)\n",
      "Requirement already satisfied: qdldl in /lnet/work/people/kasner/virtualenv/factgenie/lib/python3.10/site-packages (from osqp>=0.6.2->cvxpy>=1.0.25->pygamma-agreement) (0.1.7.post5)\n",
      "Requirement already satisfied: click>=8.0.0 in /lnet/work/people/kasner/virtualenv/factgenie/lib/python3.10/site-packages (from typer>=0.12.1->pyannote.database>=4.1->pygamma-agreement) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /lnet/work/people/kasner/virtualenv/factgenie/lib/python3.10/site-packages (from typer>=0.12.1->pyannote.database>=4.1->pygamma-agreement) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /lnet/work/people/kasner/virtualenv/factgenie/lib/python3.10/site-packages (from typer>=0.12.1->pyannote.database>=4.1->pygamma-agreement) (13.9.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /lnet/work/people/kasner/virtualenv/factgenie/lib/python3.10/site-packages (from rich>=10.11.0->typer>=0.12.1->pyannote.database>=4.1->pygamma-agreement) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /lnet/work/people/kasner/virtualenv/factgenie/lib/python3.10/site-packages (from rich>=10.11.0->typer>=0.12.1->pyannote.database>=4.1->pygamma-agreement) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /lnet/work/people/kasner/virtualenv/factgenie/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.12.1->pyannote.database>=4.1->pygamma-agreement) (0.1.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pygamma-agreement cylp pandas numpy tqdm scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing inter-annotator agreement (IAA) with factgenie\n",
    "\n",
    "This notebook shows how to compute inter-annotator agreement (IAA) between two annotator groups.\n",
    "\n",
    "### Input data\n",
    "For using the notebook, you will need the CSV files generated by factgenie for computing inter-annotator agreement:\n",
    "- `dataset_level_counts.csv`\n",
    "- `example_level_counts.csv`\n",
    "- `gamma_spans.csv`\n",
    "\n",
    "You can generate these files on the `/analyze` page (on the Inter-annotator agreement tab). On that page, you need to select the campaign(s) with multiple annotators per example and select `Export data files`.\n",
    "\n",
    "### Annotator groups\n",
    "We will compute the correlation between two **annotator groups**. Each annotator group has an id in the format `{campaign_id}-anngroup-{group_idx}`. That means that it uniquely defines the ordinal number of the annotator within a specific campaign.\n",
    "\n",
    "#### Single campaign\n",
    "You can compute IAA between annotators within a single campaign.\n",
    "\n",
    "Example: in the campaign `llm-eval-1`, you used two annotators per example. Then you want to measure agreement between `llm-eval-1-anngroup-0` and `llm-eval-1-anngroup-1`.\n",
    "\n",
    "#### Multiple campaigns\n",
    "You can compute IAA between annotators in multiple campaigns **if these campaigns were annotating the same outputs**.\n",
    "\n",
    "Example: you ran campaigns `llm-eval-1` and `llm-eval-2` over the same set of examples. Then you will measure agreement between `llm-eval-1-anngroup-0` and `llm-eval-2-anngroup-0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import pygamma_agreement as pa\n",
    "import traceback\n",
    "from pyannote.core import Segment\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Set the directory where the csv files are located here\n",
    "csv_path = \".\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pearson r\n",
    "\n",
    "First, we will use the **Pearson correlation coefficient** to measure the agreement between two annotators.\n",
    "\n",
    "Specifically, we will measure how much the **error counts** agree. \n",
    "\n",
    "In the ideal case, both annotators annotated the **same amount of errors of each category** for each example. The Pearson r coefficient will help us to quantify to which extent it is true. The value of 1 signifies perfect *positive linear correlation*, 0 signifies no linear correlation, -1 signifies perfect *negative linear correllation*.\n",
    "\n",
    "We will compare both the example-level correlation, which is more strict, and dataset-level (or, more precisely, dataset-split-setup_id-level) correlation, which is more lenient.\n",
    "\n",
    "## Levels\n",
    "\n",
    "### Dataset-level\n",
    "Pearson r between two annotators computed over a list of average error counts for each (dataset, split, setup_id) combination.\n",
    "\n",
    "### Example-level\n",
    "Pearson r between two annotators computed over a list of error counts for each (dataset, split, setup_id, example_idx) combination.\n",
    "\n",
    "## Average type\n",
    "\n",
    "### Micro-average\n",
    "A coefficient computed over concatenated results from all the categories.\n",
    "\n",
    "### Macro-average\n",
    "An average of coefficients computed separately for each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pearson_r(csv_path, group1, group2):\n",
    "    # Load data\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    group1_data = df[df['annotator_group_id'] == group1]\n",
    "    group2_data = df[df['annotator_group_id'] == group2]\n",
    "    \n",
    "    group1_counts = list(group1_data[\"count\"])\n",
    "    group2_counts = list(group2_data[\"count\"])\n",
    "\n",
    "    # Micro correlation - correlation of counts\n",
    "    micro_corr = pearsonr(group1_counts, group2_counts)[0]\n",
    "\n",
    "    # Macro correlation - average of per-type correlations\n",
    "    type_corrs = []\n",
    "    for ann_type in df['annotation_type'].unique():\n",
    "        g1_type = list(group1_data[group1_data['annotation_type'] == ann_type][\"count\"])\n",
    "        g2_type = list(group2_data[group2_data['annotation_type'] == ann_type][\"count\"])\n",
    "\n",
    "        type_corrs.append(pearsonr(g1_type, g2_type)[0])\n",
    "    \n",
    "    macro_corr = np.mean(type_corrs)\n",
    "    \n",
    "    return {'micro': micro_corr, 'macro': macro_corr, 'category_correlations': type_corrs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './dataset_level_counts.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m csv_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcsv_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlevel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_level_counts.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m groups \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquintd1-gpt-4-anngroup-0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquintd1-human-anngroup-0\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m correlations \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_pearson_r\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlevel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-level correlations between \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgroups[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgroups[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m==============================================\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[48], line 3\u001b[0m, in \u001b[0;36mcompute_pearson_r\u001b[0;34m(csv_path, group1, group2)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_pearson_r\u001b[39m(csv_path, group1, group2):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# Load data\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     group1_data \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mannotator_group_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m group1]\n\u001b[1;32m      6\u001b[0m     group2_data \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mannotator_group_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m group2]\n",
      "File \u001b[0;32m/lnet/work/people/kasner/virtualenv/factgenie/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/lnet/work/people/kasner/virtualenv/factgenie/lib/python3.10/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/lnet/work/people/kasner/virtualenv/factgenie/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/lnet/work/people/kasner/virtualenv/factgenie/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/lnet/work/people/kasner/virtualenv/factgenie/lib/python3.10/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './dataset_level_counts.csv'"
     ]
    }
   ],
   "source": [
    "\n",
    "for level in [\"dataset\", \"example\"]:\n",
    "    csv_filename = f\"{csv_path}/{level}_level_counts.csv\"\n",
    "\n",
    "    groups = ('quintd1-gpt-4-anngroup-0', 'quintd1-human-anngroup-0')\n",
    "    correlations = compute_pearson_r(csv_filename, *groups)\n",
    "\n",
    "    print(f\"{level}-level correlations between {groups[0]} and {groups[1]}\")\n",
    "    print(\"==============================================\")\n",
    "\n",
    "    print(f\"Micro Pearson-r: {correlations['micro']:.3f}\")\n",
    "    print(\"==============================================\")\n",
    "\n",
    "    for i, corr in enumerate(correlations['category_correlations']):\n",
    "        print(f\"Category {i}: {corr:.3f}\")\n",
    "    print(\"----------------------------------------------\")\n",
    "\n",
    "    print(f\"Macro Pearson-r: {correlations['macro']:.3f}\")\n",
    "    print(\"==============================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gamma (γ) score\n",
    "Second, we compute the gamma (γ) score between the two annotator groups.\n",
    "\n",
    "This score suitable for computing IAA in cases where are both (1) determining span positions and (2) categorizing the spans.\n",
    "\n",
    "The γ score considers the best alignment between the spans and computes the value based on the number of local dissimilarities. The score will help us to quantify the correlation not just between the error counts, but also their exact **positions** on top of the output text.\n",
    "\n",
    "For full description, please refer to the original paper [Mathet et al. (2015)](https://doi.org/10.1162/COLI_a_00227).\n",
    "\n",
    "For Python, the score is implemented in the [pygamma-agreement](https://pygamma-agreement.readthedocs.io/en/latest/index.html) library.\n",
    "\n",
    "**Note that computing the score is computationally intensive. Consider saving intermediate per-example scores in case you need to repeat the experiments.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gamma(span_index, dissim, precision_level=\"low\"):\n",
    "    gamma_scores = []\n",
    "    running_avg = 0\n",
    "    \n",
    "    # Group examples\n",
    "    groups = list(span_index.groupby([\"dataset\", \"split\", \"setup_id\", \"example_idx\"]))\n",
    "    \n",
    "    # Create progress bar\n",
    "    pbar = tqdm(total=len(groups), desc='Computing gamma score')\n",
    "    \n",
    "    for idx, (i, group) in enumerate(groups, 1):\n",
    "        try:\n",
    "            # Add each annotation to continuum\n",
    "            continuum = pa.Continuum()\n",
    "\n",
    "            if group.annotator_group_id.unique().shape[0] < 2:\n",
    "                print(f\"Skipping example {idx} due to insufficient annotators\")\n",
    "                gamma_scores.append(0.0)\n",
    "                running_avg = np.mean(gamma_scores)\n",
    "                pbar.set_postfix({'avg_gamma': f'{running_avg:.3f}'})\n",
    "                pbar.update(1)\n",
    "                continue\n",
    "\n",
    "            for j, row in group.iterrows():\n",
    "                # make sure we do not add empty segments\n",
    "                if row[\"annotation_start\"] == row[\"annotation_end\"]:\n",
    "                    continue\n",
    "\n",
    "                continuum.add(\n",
    "                    str(row[\"annotator_group_id\"]),\n",
    "                    Segment(row[\"annotation_start\"], row[\"annotation_end\"]),\n",
    "                    str(row[\"annotation_type\"]),\n",
    "                )\n",
    "\n",
    "            # Temporarily increase logging level to suppress output\n",
    "            logging.getLogger().setLevel(logging.WARNING)\n",
    "            gamma_results = continuum.compute_gamma(dissim, soft=True, precision_level=precision_level)\n",
    "            logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "            gamma_scores.append(gamma_results.gamma)\n",
    "            running_avg = np.mean(gamma_scores)\n",
    "            \n",
    "            # Update progress bar with current average\n",
    "            pbar.set_postfix({'avg_gamma': f'{running_avg:.3f}'})\n",
    "            pbar.update(1)\n",
    "        except Exception as e:\n",
    "            traceback.print_exc()\n",
    "            print(f\"Error computing gamma for example {idx}\")\n",
    "            gamma_scores.append(0.0)\n",
    "            running_avg = np.mean(gamma_scores)\n",
    "            pbar.set_postfix({'avg_gamma': f'{running_avg:.3f}'})\n",
    "            pbar.update(1)\n",
    "    \n",
    "    pbar.close()\n",
    "    return float(np.mean(gamma_scores)) if gamma_scores else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_spans = pd.read_csv(f\"{csv_path}/gamma_spans.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Higher precision_level will result in more accurate gamma scores, but will take longer to compute\n",
    "precision_level = \"low\"\n",
    "\n",
    "# `alpha`: coefficient weighting the *positional* dissimilarity value, defaults to 1\n",
    "alpha = 1\n",
    "# `beta`: coefficient weighting the *categorical* dissimilarity value, defaults to 1\n",
    "beta = 1\n",
    "# `delta_empty`: empty dissimilarity value, defaults to 1\n",
    "dissim = pa.CombinedCategoricalDissimilarity(delta_empty=1, alpha=1, beta=1)\n",
    "gamma = compute_gamma(gamma_spans, dissim, precision_level=precision_level)\n",
    "\n",
    "print(f\"Gamma score: {gamma:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
